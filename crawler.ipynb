{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crawler.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOoMrTduQsuYbSlVTCXHrgd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nghiaphan177/Truyvanttdpt/blob/main/crawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq0xbrhL_3ml"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Uc_2Ao_71X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc0ce4a-381f-4c71-8db6-4f2eb4210a7a"
      },
      "source": [
        "cd data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12bZFg-bCsSh"
      },
      "source": [
        "import requests\n",
        "import bs4\n",
        "import datetime\n",
        "import re\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7umjAuhDer4"
      },
      "source": [
        "def sendRequest(url):\n",
        "  while True:\n",
        "    try:\n",
        "      rp = requests.get(url, timeout=1)\n",
        "      break\n",
        "    except:\n",
        "      continue\n",
        "  bs4Rp = bs4.BeautifulSoup(rp.text,\"html.parser\")\n",
        "  return bs4Rp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OiLhlR5DTMD"
      },
      "source": [
        "def filterPtag(pTag):\n",
        "  if not pTag.attrs.get('class', False):\n",
        "    return False\n",
        "  if 'Image' in pTag.attrs['class']:\n",
        "    return False\n",
        "  if pTag.attrs.get('style', False):\n",
        "    return False\n",
        "  if pTag.attrs.get('align', False):\n",
        "    return False\n",
        "  return True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzvR-8InEA1m"
      },
      "source": [
        "def isText(htmlArticle):\n",
        "  tag = htmlArticle.find('meta', {'name' : 'its_type'})\n",
        "  if tag.attrs['content'] == 'text':\n",
        "    return True\n",
        "  return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_LdJz4MG5Vi"
      },
      "source": [
        "def getContent(urlPage):\n",
        "  htmlArticle = sendRequest(urlPage)\n",
        "  contentPage = ''\n",
        "  if not isText(htmlArticle):\n",
        "    return contentPage\n",
        "  allPtags = htmlArticle.find_all('p')\n",
        "  usefulPtags = filter(filterPtag, allPtags)\n",
        "  for pTag in usefulPtags:\n",
        "    text = pTag.text\n",
        "    contentPage = contentPage + '\\n' + text \n",
        "  return contentPage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCaeu298C5mu"
      },
      "source": [
        "def crawlData(rootUrl, folder2Save, amount):\n",
        "  # get the current path\n",
        "  currPath = os.getcwd()\n",
        "  # check if folder2Save is exist else create\n",
        "  dir = os.path.join(currPath, folder2Save)\n",
        "  if not os.path.exists(dir):\n",
        "    os.mkdir(dir)\n",
        "\n",
        "  url = rootUrl\n",
        "  \n",
        "  number = 0\n",
        "  i = 0\n",
        "  flag = True\n",
        "  while flag:\n",
        "    # Find all the links of the a category page \n",
        "    bs4Rp = sendRequest(url)\n",
        "    articleLinks = set(re.findall(r'href=\\\"(.+\\.html)', str(bs4Rp)))\n",
        "    # Go to the article page and get the content\n",
        "    for articleLink in articleLinks:\n",
        "      contentPage = getContent(articleLink)\n",
        "      if contentPage == '':\n",
        "        continue\n",
        "      number += 1\n",
        "      nameFile = f'data-{number}.txt'\n",
        "      pathFileTxt = os.path.join(dir, nameFile)\n",
        "      with open(pathFileTxt, 'a+', encoding='utf-8') as f:\n",
        "        f.write(contentPage)\n",
        "      if number == amount:\n",
        "        flag = False\n",
        "        break\n",
        "    # set up url to  the next page \n",
        "    i += 1\n",
        "    url = rootUrl + f\"/p{i}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH6TBQa16xGq"
      },
      "source": [
        "rootUrl = 'https://vnexpress.net/phap-luat'\n",
        "folder2Save = 'phap-luat'\n",
        "amount = 20\n",
        "crawlData(rootUrl, folder2Save, amount)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPgWvGTARscG"
      },
      "source": [
        "**Lưu data thành tập tin csv có 2 cột là content và category**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szlAsOXfJDhb"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okP9TWEDNrmP"
      },
      "source": [
        "dataPath = '/content/data'\n",
        "df = pd.DataFrame()\n",
        "for dir in os.listdir(dataPath):\n",
        "  if dir == '.ipynb_checkpoints':\n",
        "    continue\n",
        "  pathDir = os.path.join(dataPath, dir)\n",
        "  for txtFile in os.listdir(pathDir):\n",
        "    pathTxtFile = os.path.join(pathDir, txtFile)\n",
        "    with open(pathTxtFile, 'r', encoding='utf-8') as f:\n",
        "      text = f.read()\n",
        "    df  = df.append([[text, dir]], ignore_index=True)\n",
        "df = df.rename(columns={0 : 'content', 1 : 'category'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQH90Wn7eRcD"
      },
      "source": [
        "import pickle\n",
        "with open('data.csv') as f:\n",
        "  pickle.dumb(df, f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}