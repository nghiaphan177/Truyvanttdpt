{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Best_Model_Selection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqilm6pB4IIH"
      },
      "source": [
        "# Best Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEAgmrMl4IIH"
      },
      "source": [
        "Now that we have trained all the models, let's select the one we'll use for the application. We'll need to get the performance metrics generated in every model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOigpPLT58ft",
        "outputId": "592fb6a4-25d0-4733-a921-dde34cc896f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNyehxTU4IIH"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KswvOhd4IIH"
      },
      "source": [
        "path_pickles = \"/content/drive/MyDrive/Mo_dels/\"\n",
        "\n",
        "list_pickles = [\n",
        "    \"df_models_gbc.pickle\",\n",
        "    \"df_models_lrc.pickle\",\n",
        "    \"df_models_mnbc.pickle\",\n",
        "    \"df_models_rfc.pickle\",\n",
        "    \"df_models_svc.pickle\"\n",
        "]\n",
        "\n",
        "df_summary = pd.DataFrame()\n",
        "\n",
        "for pickle_ in list_pickles:\n",
        "    \n",
        "    path = path_pickles +pickle_\n",
        "    \n",
        "    with open(path, 'rb') as data:\n",
        "        df = pickle.load(data)\n",
        "\n",
        "    df_summary = df_summary.append(df)\n",
        "\n",
        "df_summary = df_summary.reset_index().drop('index', axis=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iHEhWJN4IIH"
      },
      "source": [
        "Let's see the summary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dmAr25f4IIH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a22f95f6-3640-42c1-ec37-76b67cf13a0b"
      },
      "source": [
        "df_summary"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Training Set Accuracy</th>\n",
              "      <th>Test Set Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.977778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.984314</td>\n",
              "      <td>0.977778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Multinomial Naïve Bayes</td>\n",
              "      <td>0.965490</td>\n",
              "      <td>0.973333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.973333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.989804</td>\n",
              "      <td>0.968889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Model  Training Set Accuracy  Test Set Accuracy\n",
              "0        Gradient Boosting               1.000000           0.977778\n",
              "1      Logistic Regression               0.984314           0.977778\n",
              "2  Multinomial Naïve Bayes               0.965490           0.973333\n",
              "3            Random Forest               1.000000           0.973333\n",
              "4                      SVM               0.989804           0.968889"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0LOayxl4III"
      },
      "source": [
        "And sort it by **Test Set Accuracy**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsyRzzeP4III",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "0281adcf-12b5-4687-e3a0-7ddb9fd9e7f5"
      },
      "source": [
        "df_summary.sort_values('Test Set Accuracy', ascending=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Training Set Accuracy</th>\n",
              "      <th>Test Set Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.977778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.984314</td>\n",
              "      <td>0.977778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Multinomial Naïve Bayes</td>\n",
              "      <td>0.965490</td>\n",
              "      <td>0.973333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.973333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.989804</td>\n",
              "      <td>0.968889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Model  Training Set Accuracy  Test Set Accuracy\n",
              "0        Gradient Boosting               1.000000           0.977778\n",
              "1      Logistic Regression               0.984314           0.977778\n",
              "2  Multinomial Naïve Bayes               0.965490           0.973333\n",
              "3            Random Forest               1.000000           0.973333\n",
              "4                      SVM               0.989804           0.968889"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUnp7fMh4III"
      },
      "source": [
        "The Gradient Boosting, Logistic Regression and Random Forest seem to be overfit, so we'll discard them. From the remaining models, we will choose the **Multinomial Naïve Bayes** since it has the highest Test Set Accuracy."
      ]
    }
  ]
}