{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Best_Model_Selection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqilm6pB4IIH"
      },
      "source": [
        "# Best Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEAgmrMl4IIH"
      },
      "source": [
        "Now that we have trained all the models, let's select the one we'll use for the application. We'll need to get the performance metrics generated in every model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOigpPLT58ft",
        "outputId": "592fb6a4-25d0-4733-a921-dde34cc896f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNyehxTU4IIH"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KswvOhd4IIH"
      },
      "source": [
        "path_pickles = \"/content/drive/MyDrive/Mo_dels/\"\n",
        "\n",
        "list_pickles = [\n",
        "    \"df_models_gbc.pickle\",\n",
        "    \"df_models_lrc.pickle\",\n",
        "    \"df_models_mnbc.pickle\",\n",
        "    \"df_models_rfc.pickle\",\n",
        "    \"df_models_svc.pickle\"\n",
        "]\n",
        "\n",
        "df_summary = pd.DataFrame()\n",
        "\n",
        "for pickle_ in list_pickles:\n",
        "    \n",
        "    path = path_pickles +pickle_\n",
        "    \n",
        "    with open(path, 'rb') as data:\n",
        "        df = pickle.load(data)\n",
        "\n",
        "    df_summary = df_summary.append(df)\n",
        "\n",
        "df_summary = df_summary.reset_index().drop('index', axis=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iHEhWJN4IIH"
      },
      "source": [
        "Let's see the summary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dmAr25f4IIH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a22f95f6-3640-42c1-ec37-76b67cf13a0b"
      },
      "source": [
        "df_summary"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Training Set Accuracy</th>\n",
              "      <th>Test Set Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.977778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.984314</td>\n",
              "      <td>0.977778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Multinomial Na誰ve Bayes</td>\n",
              "      <td>0.965490</td>\n",
              "      <td>0.973333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.973333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.989804</td>\n",
              "      <td>0.968889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Model  Training Set Accuracy  Test Set Accuracy\n",
              "0        Gradient Boosting               1.000000           0.977778\n",
              "1      Logistic Regression               0.984314           0.977778\n",
              "2  Multinomial Na誰ve Bayes               0.965490           0.973333\n",
              "3            Random Forest               1.000000           0.973333\n",
              "4                      SVM               0.989804           0.968889"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0LOayxl4III"
      },
      "source": [
        "And sort it by **Test Set Accuracy**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsyRzzeP4III",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "0281adcf-12b5-4687-e3a0-7ddb9fd9e7f5"
      },
      "source": [
        "df_summary.sort_values('Test Set Accuracy', ascending=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Training Set Accuracy</th>\n",
              "      <th>Test Set Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gradient Boosting</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.977778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.984314</td>\n",
              "      <td>0.977778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Multinomial Na誰ve Bayes</td>\n",
              "      <td>0.965490</td>\n",
              "      <td>0.973333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.973333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.989804</td>\n",
              "      <td>0.968889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Model  Training Set Accuracy  Test Set Accuracy\n",
              "0        Gradient Boosting               1.000000           0.977778\n",
              "1      Logistic Regression               0.984314           0.977778\n",
              "2  Multinomial Na誰ve Bayes               0.965490           0.973333\n",
              "3            Random Forest               1.000000           0.973333\n",
              "4                      SVM               0.989804           0.968889"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUnp7fMh4III"
      },
      "source": [
        "The Gradient Boosting, Logistic Regression and Random Forest seem to be overfit, so we'll discard them. From the remaining models, we will choose the **Multinomial Na誰ve Bayes** since it has the highest Test Set Accuracy."
      ]
    }
  ]
}